diff --git a/__pycache__/denoise.cpython-36.pyc b/__pycache__/denoise.cpython-36.pyc
deleted file mode 100644
index 3fbe811..0000000
Binary files a/__pycache__/denoise.cpython-36.pyc and /dev/null differ
diff --git a/__pycache__/load_data.cpython-36.pyc b/__pycache__/load_data.cpython-36.pyc
index a38cca8..bacf2a5 100644
Binary files a/__pycache__/load_data.cpython-36.pyc and b/__pycache__/load_data.cpython-36.pyc differ
diff --git a/__pycache__/models.cpython-36.pyc b/__pycache__/models.cpython-36.pyc
index d2085b0..a8f18c5 100644
Binary files a/__pycache__/models.cpython-36.pyc and b/__pycache__/models.cpython-36.pyc differ
diff --git a/__pycache__/utils.cpython-36.pyc b/__pycache__/utils.cpython-36.pyc
index 1b3830c..ab5bcf3 100644
Binary files a/__pycache__/utils.cpython-36.pyc and b/__pycache__/utils.cpython-36.pyc differ
diff --git a/classify.py b/classify.py
index 92b586f..ccbafb3 100644
--- a/classify.py
+++ b/classify.py
@@ -35,22 +35,6 @@ def main():
     ''' Load data '''
     loader_sup, loader_unsup, loader_val_sup = nyu_image_loader("../ssl_data_96", 32)
 
-    ''' Do Validation '''
-    if args.valid:
-        print("Loading checkpoint...")
-        classifier.ae.load_state_dict(torch.load("./weights/ae.pkl")) # TODO: - Check weight loading is successful
-        dataiter = iter(loader_val_sup)
-        images, labels = dataiter.next()
-        #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
-        imshow(torchvision.utils.make_grid(images))
-
-        images = Variable(images.cuda())
-
-        decoded_imgs = classifier(images)[1]
-        imshow(torchvision.utils.make_grid(decoded_imgs.data))
-
-        exit(0)
-
     # Define an optimizer and criterion
     criterion = nn.MSELoss() # TODO: - Find something better
     optimizer = optim.Adam(classifier.parameters())
@@ -73,7 +57,7 @@ def main():
             # ============ Logging ============
             running_loss += loss.data
             if i % 2000 == 1999:
-                wandb.log({"Validation Accuracy": running_loss / 2000,
+                wandb.log({"Validation Loss": running_loss / 2000,
                            "Epoch" : epoch + 1,
                            "Iteration" : i+1,
                            })
@@ -88,5 +72,19 @@ def main():
     torch.save(classifier.state_dict(), "./weights/ae.pkl")
 
 
+    ''' Do Validation '''
+    if args.valid:
+        print("Loading checkpoint...")
+        classifier.ae.load_state_dict(torch.load("./weights/ae.pkl"))
+        dataiter = iter(loader_val_sup)
+        images, labels = dataiter.next()
+        # print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
+        images = Variable(images.cuda())
+        decoded_imgs = classifier.ae(images)[1]
+        if args.verbose:
+            imshow(torchvision.utils.make_grid(images))
+            imshow(torchvision.utils.make_grid(decoded_imgs.data))
+
+
 if __name__ == '__main__':
     main()
diff --git a/load_data.py b/load_data.py
index 6ae42b3..e5cca5a 100644
--- a/load_data.py
+++ b/load_data.py
@@ -47,7 +47,6 @@ def cifar_image_loader(path='./data', batch_size=16):
     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
     # CIFAR-10 Classes
-    classes = ('plane', 'car', 'bird', 'cat',
-               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
+    val_set = testloader
 
-    return trainloader, testloader, classes
+    return trainloader, testloader, val_set
diff --git a/models.py b/models.py
index 52920b0..adad5da 100644
--- a/models.py
+++ b/models.py
@@ -41,9 +41,9 @@ class Classifier(nn.Module):
         super(Classifier, self).__init__()
         self.ae = Autoencoder()
         self.mlp = nn.Sequential(
-            nn.Linear(3*96*96, 1000), # TODO: - Decide what h_dim to use here
+            nn.Linear(6*6*96, 256), # TODO: - Decide what h_dim to use here
             nn.ReLU(),
-            nn.Linear(1000, 10))
+            nn.Linear(256, 10))
         self.softmax = nn.Softmax()
 
     def forward(self, x):
diff --git a/denoise.py b/noise.py
similarity index 60%
rename from denoise.py
rename to noise.py
index e9df329..044a7c6 100644
--- a/denoise.py
+++ b/noise.py
@@ -1,4 +1,3 @@
-import numpy as np
 import torch
 
 def corrupt_input(corr_type, data, v):
@@ -6,7 +5,7 @@ def corrupt_input(corr_type, data, v):
     if corr_type == 'mask':
         x_corrupted = masking_noise(data, v)
 
-    elif corr_type == 's&p':
+    elif corr_type == 'sp':
         x_corrupted = salt_and_pepper(data, v)
 
     elif corr_type == 'gauss':
@@ -23,12 +22,16 @@ def corrupt_input(corr_type, data, v):
 
 '''Apply masking noise by zeroing out a fraction v of the elements in X'''
 def masking_noise(X, v):
-    noise_tensor = (torch.from_numpy(np.random.uniform(0,1,X.shape)) > v).type(torch.FloatTensor)
+    noise_tensor = (torch.distributions.uniform.Uniform(0, 1).sample(X.shape) > v).type(torch.FloatTensor)
+    if torch.cuda.is_available():
+        noise_tensor = noise_tensor.type(torch.cuda.FloatTensor)
     return torch.mul(X, noise_tensor)
 
 '''Apply salt and pepper noise by setting a fraction v of the elements in X to the min and max values'''
 def salt_and_pepper(X, v):
-    rnd = torch.from_numpy(np.random.rand(X.shape[0], X.shape[1], X.shape[2], X.shape[3]))
+    rnd = torch.distributions.uniform.Uniform(0, 1).sample(X.shape)
+    if torch.cuda.is_available():
+        rnd = rnd.type(torch.cuda.FloatTensor)
     noisy = X.clone()
     noisy[rnd < v/2] = 0.
     noisy[rnd > (1 - v/2)] = 1.
@@ -36,6 +39,7 @@ def salt_and_pepper(X, v):
 
 '''Apply gaussian noise by adding values sampled from a gaussian to v of the elements in X to the min and max values'''
 def gaussian_noise(X, miu, std):
-    noise = np.random.normal(loc=miu, scale=std, size=np.shape(X))
-    noise_t = torch.from_numpy(noise).type(torch.FloatTensor)
-    return torch.add(X,noise_t)
\ No newline at end of file
+    noise = torch.distributions.normal.Normal(miu, std).sample(X.shape)
+    if torch.cuda.is_available():
+        noise = noise.type(torch.cuda.FloatTensor)
+    return torch.clamp(torch.add(X,noise),0,1)
\ No newline at end of file
diff --git a/pretrain.py b/pretrain.py
index cd8ab3d..02dcd58 100644
--- a/pretrain.py
+++ b/pretrain.py
@@ -4,7 +4,7 @@ import torch.optim as optim
 from load_data import *
 
 # This project
-from denoise import corrupt_input
+from noise import corrupt_input
 from utils import *
 
 # Torchvision
@@ -36,9 +36,9 @@ def main():
                         help="Perform validation only.", metavar='v')
     parser.add_argument("--perc_noise", '-percentage_of_noise', type=float, default=0.05,
                         help="Percentage of noise to add.", metavar='p')
-    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="mask",
+    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="sp",
                         help="Percentage of noise to add.", metavar='c')
-    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=False,
+    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=True,
                         help="Show images as you feed them in, show reconstructions as they come out.", metavar='b')
     parser.add_argument("--wandb", '-name_of_wandb_proj', type=str, default="le-project",
                         help="Name of WAND Project.", metavar='w')
@@ -51,7 +51,7 @@ def main():
     ae = create_model("pretrain")
 
     ''' Load data '''
-    loader_sup, loader_unsup, loader_val_sup = nyu_image_loader("../ssl_data_96", 32)
+    loader_sup, loader_val_sup, loader_unsup = nyu_image_loader("../ssl_data_96", 32)
 
     # Define an optimizer and criterion
     criterion = nn.BCELoss()
@@ -59,13 +59,13 @@ def main():
 
     wandb.watch(ae)
 
-    for epoch in range(10):
+    for epoch in range(30):
         running_loss = 0.0
-        for i, (inputs, _) in enumerate(loader_sup, 0):
+        for i, (inputs, _) in enumerate(loader_unsup, 0):
             inputs = get_torch_vars(inputs)
-            print(inputs.shape)
             noised = corrupt_input(args.corr_type, inputs, args.perc_noise)
-            print("Iteration ", i)
+            noised = get_torch_vars(noised)
+
             # ============ Forward ============
             encoded, outputs = ae(noised)
             loss = criterion(outputs, inputs)
@@ -81,7 +81,7 @@ def main():
             # ============ Logging ============
             running_loss += loss.data
             if i % 2000 == 1999:
-                wandb.log({"Training Accuracy": running_loss / 2000,
+                wandb.log({"Training Loss": running_loss / 2000,
                            "Epoch" : epoch + 1,
                            "Iteration" : i + 1,
                            })
@@ -89,11 +89,11 @@ def main():
                       (epoch + 1, i + 1, running_loss / 2000))
                 running_loss = 0.0
 
-    ''' Save Trained Model '''
-    print('Done Training. Saving Model...')
-    if not os.path.exists('./weights'):
-        os.mkdir('./weights')
-    torch.save(ae.state_dict(), "./weights/ae.pkl")
+        ''' Save Trained Model '''
+        print('Saving Model after epoch ', epoch)
+        if not os.path.exists('./weights'):
+            os.mkdir('./weights')
+        torch.save(ae.state_dict(), "./weights/ae.pkl")
 
     ''' Do Validation '''
     if args.valid:
@@ -102,12 +102,11 @@ def main():
         dataiter = iter(loader_val_sup)
         images, labels = dataiter.next()
         # print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
-        imshow(torchvision.utils.make_grid(images))
-
         images = Variable(images.cuda())
-
         decoded_imgs = ae(images)[1]
-        imshow(torchvision.utils.make_grid(decoded_imgs.data))
+        if args.verbose:
+            imshow(torchvision.utils.make_grid(images))
+            imshow(torchvision.utils.make_grid(decoded_imgs.data))
 
         exit(0)
 
diff --git a/utils.py b/utils.py
index 09ae300..c59144c 100644
--- a/utils.py
+++ b/utils.py
@@ -5,7 +5,6 @@ from models import Autoencoder, Classifier
 import torch
 from torch.autograd import Variable
 import numpy as np
-import matplotlib.pyplot as plt
 
 ''' Instantiate Model '''
 def create_model(model_type):
@@ -45,6 +44,7 @@ def get_torch_vars(x):
 
 ''' Display Image '''
 def imshow(img):
+    import matplotlib.pyplot as plt
     npimg = img.cpu().numpy()
     plt.axis('off')
     plt.imshow(np.transpose(npimg, (1, 2, 0)))
diff --git a/wandb/debug.log b/wandb/debug.log
index 42c4e1e..4f947c0 100644
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1,40 +1,15 @@
-2019-04-29 12:41:30,272 DEBUG   MainThread:19310 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
-2019-04-29 12:41:30,278 DEBUG   MainThread:19310 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,294 DEBUG   MainThread:19310 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,320 DEBUG   MainThread:19310 [run_manager.py:__init__():452] Initialized sync for le-project/e7romswt
-2019-04-29 12:41:30,324 INFO    MainThread:19310 [run_manager.py:wrap_existing_process():986] wrapping existing process 19300
-2019-04-29 12:41:30,332 DEBUG   MainThread:19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
-2019-04-29 12:41:30,381 DEBUG   MainThread:19310 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
-2019-04-29 12:41:30,391 INFO    MainThread:19310 [run_manager.py:init_run():810] system metrics and metadata threads started
-2019-04-29 12:41:30,391 INFO    MainThread:19310 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
-2019-04-29 12:41:30,403 DEBUG   Thread-13 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:30,510 DEBUG   Thread-13 :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
-2019-04-29 12:41:30,514 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():900] saving patches
-2019-04-29 12:41:30,514 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,527 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,542 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,556 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,590 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():902] saving pip packages
-2019-04-29 12:41:30,591 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():904] initializing streaming files api
-2019-04-29 12:41:30,592 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():911] unblocking file change observer, beginning sync with W&B servers
-2019-04-29 12:41:30,592 INFO    MainThread:19310 [run_manager.py:wrap_existing_process():1003] informing user process we are ready to proceed
-2019-04-29 12:41:30,592 INFO    MainThread:19310 [run_manager.py:_sync_etc():1059] entering loop for messages from user process
-2019-04-29 12:41:31,280 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/wandb-metadata.json
-2019-04-29 12:41:31,281 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/diff.patch
-2019-04-29 12:41:31,281 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/config.yaml
-2019-04-29 12:41:31,290 DEBUG   Thread-2  :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:31,388 DEBUG   Thread-2  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 629
-2019-04-29 12:41:31,390 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/requirements.txt
-2019-04-29 12:41:31,395 DEBUG   Thread-14 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:31,472 DEBUG   Thread-14 :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 743
-2019-04-29 12:41:31,478 DEBUG   Thread-14 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): storage.googleapis.com:443
-2019-04-29 12:41:31,778 DEBUG   Thread-14 :19310 [connectionpool.py:_make_request():393] https://storage.googleapis.com:443 "PUT /wandb-production.appspot.com/dlc423/le-project/e7romswt/config.yaml?Expires=1556556151&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=HW8FtP3cBeCXe4Dx5JmDGaswSgDLDPkYestYt%2FGjFQRbM00Fqcwac4eKvGxGLnGrSxrDTvSsitTD%2F7w%2F3DzILAosw2aGLBFLTgRw23chxKp8vQB%2FH4x5PicaPyqA3PZIJPTNp6gdQtCwfU4b3Xfn4HHx4qheNYlIp4iFiSM5SQragfG3QS8sVPnyLmrCONzkSSUC%2BeTsupIQxQD385K8YmEEAGb2pvm2i16bQfksdYmljU%2FQC9yipl9REySOxVGPRuSLHFldWDdCSbRYKeoE0fRrp87U9BV5W7%2B2qkOHBvviPaJf1oXIFGUxY0%2FpfBhRzSWiyC5RqNtHN203CR1DfA%3D%3D HTTP/1.1" 200 0
-2019-04-29 12:41:32,609 DEBUG   Thread-6  :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:32,710 DEBUG   Thread-6  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/e7romswt/file_stream HTTP/1.1" 200 312
-2019-04-29 12:41:36,658 DEBUG   Thread-6  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/e7romswt/file_stream HTTP/1.1" 200 312
-2019-04-29 12:41:37,296 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/wandb-history.jsonl
-2019-04-29 12:41:37,524 INFO    MainThread:19310 [run_manager.py:_sync_etc():1110] process received interrupt signal, shutting down
-2019-04-29 12:41:37,524 INFO    MainThread:19310 [run_manager.py:_sync_etc():1163] closing log streams and sending exitcode to W&B
-2019-04-29 12:41:37,525 INFO    MainThread:19310 [run_manager.py:shutdown():918] shutting down system stats and metadata service
-9310 [e7romswt:run_manager.py:_sync_etc():1163] closing log streams and sending exitcode to W&B
-2019-04-29 12:41:37,525 INFO    MainThread:19310 [e7romswt:run_manager.py:shutdown():918] shutting down system stats and metadata service
+2019-04-30 13:43:31,423 DEBUG   MainThread:51710 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
+2019-04-30 13:43:31,428 DEBUG   MainThread:51710 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 13:43:31,440 DEBUG   MainThread:51710 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 13:43:31,461 DEBUG   MainThread:51710 [run_manager.py:__init__():452] Initialized sync for le-project/toi6ze4g
+2019-04-30 13:43:31,464 INFO    MainThread:51710 [run_manager.py:wrap_existing_process():986] wrapping existing process 51705
+2019-04-30 13:43:31,468 DEBUG   MainThread:51710 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
+2019-04-30 13:43:31,508 DEBUG   MainThread:51710 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
+2019-04-30 13:43:31,520 INFO    MainThread:51710 [run_manager.py:init_run():810] system metrics and metadata threads started
+2019-04-30 13:43:31,520 INFO    MainThread:51710 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
+2019-04-30 13:43:31,527 DEBUG   Thread-13 :51710 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
+2019-04-30 13:43:31,627 DEBUG   Thread-13 :51710 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 355
+2019-04-30 13:43:31,631 INFO    Thread-13 :51710 [run_manager.py:_upsert_run():900] saving patches
+2019-04-30 13:43:31,631 DEBUG   Thread-13 :51710 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 13:43:31,643 DEBUG   Thread-13 :51710 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 13:43:31,655 DEBUG   Thread-13 :51710 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
