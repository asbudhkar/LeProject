diff --git a/__pycache__/noise.cpython-36.pyc b/__pycache__/noise.cpython-36.pyc
index 30cb3b2..285dd9a 100644
Binary files a/__pycache__/noise.cpython-36.pyc and b/__pycache__/noise.cpython-36.pyc differ
diff --git a/__pycache__/utils.cpython-36.pyc b/__pycache__/utils.cpython-36.pyc
index 12fcab0..ac90663 100644
Binary files a/__pycache__/utils.cpython-36.pyc and b/__pycache__/utils.cpython-36.pyc differ
diff --git a/classify.py b/classify.py
index e23fc9c..55d65af 100644
--- a/classify.py
+++ b/classify.py
@@ -40,10 +40,7 @@ def main():
 
 
     # Create model
-    classifier = create_model("classify")
-
-    # Load pretrained weights
-    classifier.ae.load_state_dict(torch.load(pretrained_weight_name))
+    classifier = create_model("classify", ckpt=pretrained_weight_name)
 
     ''' Load data '''
     loader_sup, loader_val_sup, loader_unsup = nyu_image_loader("../ssl_data_96", 32)
@@ -54,8 +51,11 @@ def main():
 
     wandb.watch(classifier)
 
-    for epoch in range(100):
+    # TODO: - Add accuracy @1 @5
+
+    for epoch in range(20):
         running_loss = 0.0
+
         for i, (inputs, labels) in enumerate(loader_sup, 0):
             inputs = get_torch_vars(inputs)
 
diff --git a/pretrain.py b/pretrain.py
index a18a91a..06e9e3b 100644
--- a/pretrain.py
+++ b/pretrain.py
@@ -33,13 +33,13 @@ def main():
                         help="Perform validation only.", metavar='v')
     parser.add_argument("--perc_noise", '-percentage_of_noise', type=float, default=0.05,
                         help="Percentage of noise to add.", metavar='p')
-    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="local_gauss",
+    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="gauss",
                         help="Percentage of noise to add.", metavar='c')
-    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=False,
+    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=True,
                         help="Show images as you feed them in, show reconstructions as they come out.", metavar='b')
     parser.add_argument("--wandb", '-name_of_wandb_proj', type=str, default="le-project",
                         help="Name of WAND Project.", metavar='w')
-    parser.add_argument("--ckpt_on", '-load_weights_from_ckpt', type=bool, default=False,
+    parser.add_argument("--ckpt_on", '-load_weights_from_ckpt', type=bool, default=True,
                         help="Name of WAND Project.", metavar='w')
     args = parser.parse_args()
 
@@ -54,9 +54,7 @@ def main():
 
 
     # Create model
-    ae = create_model("pretrain")
-    if args.ckpt_on:
-        ae.load_state_dict(pretrained_weight_name)
+    ae = create_model("pretrain", pretrained_weight_name)
 
     ''' Load data '''
     loader_sup, loader_val_sup, loader_unsup = nyu_image_loader("../ssl_data_96", 32)
@@ -73,6 +71,7 @@ def main():
             inputs = get_torch_vars(inputs)
             noised = corrupt_input(args.corr_type, inputs, args.perc_noise)
             noised = get_torch_vars(noised)
+            print("Iteration number: ", i)
 
             # ============ Forward ============
             encoded, outputs = ae(noised)
@@ -85,6 +84,7 @@ def main():
             if args.verbose:
                 imshow(inputs[0])
                 imshow(noised[0])
+                imshow(outputs[0])
 
             # ============ Logging ============
             running_loss += loss.data
diff --git a/utils.py b/utils.py
index 1a8fc49..ac7bff5 100644
--- a/utils.py
+++ b/utils.py
@@ -7,10 +7,13 @@ from torch.autograd import Variable
 import numpy as np
 
 ''' Instantiate Model '''
-def create_model(model_type):
+def create_model(model_type, ckpt=None):
     # Create and print DAE
     if model_type == "pretrain":
         ae = Autoencoder()
+        if ckpt != None:
+            pretrained_dict = torch.load(ckpt, map_location='cpu')
+            ae.load_state_dict(pretrained_dict)
         print_model("Encoder", ae.encoder, "Decoder", ae.decoder)
         if torch.cuda.is_available():
             ae = ae.cuda()
@@ -19,6 +22,9 @@ def create_model(model_type):
     # Create and print Classifier based on Pretrained DAE
     elif model_type == "classify":
         classifier = Classifier()
+        if ckpt != None:
+            pretrained_dict = torch.load(ckpt, map_location='cpu')
+            classifier.ae.load_state_dict(pretrained_dict)
         print_model("Pretrained Encoder", classifier.ae.encoder, "Classifier", classifier.mlp)
         if torch.cuda.is_available():
             classifier = classifier.cuda()
diff --git a/wandb/debug.log b/wandb/debug.log
index 2673eea..955b78c 100644
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1,35 +1,16 @@
-2019-05-01 12:37:50,510 DEBUG   MainThread:6314 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
-2019-05-01 12:37:50,515 DEBUG   MainThread:6314 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,527 DEBUG   MainThread:6314 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,544 DEBUG   MainThread:6314 [run_manager.py:__init__():452] Initialized sync for le-project/wgxz73j7
-2019-05-01 12:37:50,548 INFO    MainThread:6314 [run_manager.py:wrap_existing_process():986] wrapping existing process 6308
-2019-05-01 12:37:50,564 DEBUG   MainThread:6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
-2019-05-01 12:37:50,598 DEBUG   MainThread:6314 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
-2019-05-01 12:37:50,610 INFO    MainThread:6314 [run_manager.py:init_run():810] system metrics and metadata threads started
-2019-05-01 12:37:50,610 INFO    MainThread:6314 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
-2019-05-01 12:37:50,619 DEBUG   Thread-13 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:50,757 DEBUG   Thread-13 :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
-2019-05-01 12:37:50,761 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():900] saving patches
-2019-05-01 12:37:50,761 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,773 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,784 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,797 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,835 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():902] saving pip packages
-2019-05-01 12:37:50,838 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():904] initializing streaming files api
-2019-05-01 12:37:50,839 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():911] unblocking file change observer, beginning sync with W&B servers
-2019-05-01 12:37:50,840 INFO    MainThread:6314 [run_manager.py:wrap_existing_process():1003] informing user process we are ready to proceed
-2019-05-01 12:37:50,840 INFO    MainThread:6314 [run_manager.py:_sync_etc():1059] entering loop for messages from user process
-2019-05-01 12:37:51,518 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/requirements.txt
-2019-05-01 12:37:51,521 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/config.yaml
-2019-05-01 12:37:51,529 DEBUG   Thread-2  :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:51,619 DEBUG   Thread-2  :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 685
-2019-05-01 12:37:51,621 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/diff.patch
-2019-05-01 12:37:51,622 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-metadata.json
-2019-05-01 12:37:51,626 DEBUG   Thread-14 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:51,703 DEBUG   Thread-14 :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 747
-2019-05-01 12:37:51,708 DEBUG   Thread-14 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): storage.googleapis.com:443
-2019-05-01 12:37:52,046 DEBUG   Thread-14 :6314 [connectionpool.py:_make_request():393] https://storage.googleapis.com:443 "PUT /wandb-production.appspot.com/dlc423/le-project/wgxz73j7/config.yaml?Expires=1556728731&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=AQeyXxCkgiHXzQ4%2B%2BPKTNYnh9ZUK7he0cLUoN5Kol84UZFLkuG9x0yDOLDCowIuhwUDHx86NiNKxFa9bv03PDWn6jSQfCZHFSP8P5L0fUVzEktWYVFIA%2B6YIM2RG9L9ubb3DO1kPdx0Tnw9aMEvUCLOGZisf%2FMLWmwEvOB4Fu5K6E6CoqIgXkpA%2BSLKzR%2FH6kJ8ajuwezSx%2FqLd74qt4P5TmVSaz581Iq2D70aXPUqr16gTG939Wl2by90WVbHY9RNtip5ZOr25qtPPzErg170R3gdgzokS2TJ32m2re9M7SH%2Fl%2BhOBML5aOvOVuboaFhkVPj%2FExMamuqNzAtUb0DQ%3D%3D HTTP/1.1" 200 0
-2019-05-01 12:37:52,857 DEBUG   Thread-6  :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:52,956 DEBUG   Thread-6  :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/wgxz73j7/file_stream HTTP/1.1" 200 312
-2019-05-01 12:37:54,525 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-history.jsonl
-2019-05-01 12:37:54,525 INFO    Thread-2  :6314 [wgxz73j7:run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-history.jsonl
+2019-05-01 16:26:13,568 DEBUG   MainThread:9944 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
+2019-05-01 16:26:13,575 DEBUG   MainThread:9944 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 16:26:13,589 DEBUG   MainThread:9944 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 16:26:13,614 DEBUG   MainThread:9944 [run_manager.py:__init__():452] Initialized sync for le-project/q043otuo
+2019-05-01 16:26:13,619 INFO    MainThread:9944 [run_manager.py:wrap_existing_process():986] wrapping existing process 9938
+2019-05-01 16:26:13,628 DEBUG   MainThread:9944 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
+2019-05-01 16:26:13,663 DEBUG   MainThread:9944 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
+2019-05-01 16:26:13,677 INFO    MainThread:9944 [run_manager.py:init_run():810] system metrics and metadata threads started
+2019-05-01 16:26:13,677 INFO    MainThread:9944 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
+2019-05-01 16:26:13,687 DEBUG   Thread-13 :9944 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
+2019-05-01 16:26:13,777 DEBUG   Thread-13 :9944 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 355
+2019-05-01 16:26:13,780 INFO    Thread-13 :9944 [run_manager.py:_upsert_run():900] saving patches
+2019-05-01 16:26:13,780 DEBUG   Thread-13 :9944 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 16:26:13,793 DEBUG   Thread-13 :9944 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 16:26:13,809 DEBUG   Thread-13 :9944 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 16:26:13,827 DEBUG   Thread-13 :9944 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
