diff --git a/__pycache__/denoise.cpython-36.pyc b/__pycache__/denoise.cpython-36.pyc
index 853db6e..3fbe811 100644
Binary files a/__pycache__/denoise.cpython-36.pyc and b/__pycache__/denoise.cpython-36.pyc differ
diff --git a/__pycache__/models.cpython-36.pyc b/__pycache__/models.cpython-36.pyc
index 07f6fa4..d2085b0 100644
Binary files a/__pycache__/models.cpython-36.pyc and b/__pycache__/models.cpython-36.pyc differ
diff --git a/classify.py b/classify.py
index bd0e3ef..6b9b4c3 100644
--- a/classify.py
+++ b/classify.py
@@ -7,7 +7,11 @@ import torch.nn as nn
 import torch.optim as optim
 import torchvision
 
+import wandb
+
 def main():
+    wandb.init()
+
     # Parse Args
     parser = argparse.ArgumentParser(description="Train Autoencoder")
     parser.add_argument("--valid", action="store_true", default=False,
@@ -18,8 +22,13 @@ def main():
                         help="Percentage of noise to add.")
     parser.add_argument("--verbose", action="store_true", default=False,
                         help="Show images as you feed them in, show reconstructions as they come out.")
+    parser.add_argument("--wandb", action="store_true", default="le-project",
+                        help="Name of WAND Project.")
     args = parser.parse_args()
 
+    wandb.config.update(args)
+
+
     # Create model
     classifier = create_model("classify")
 
@@ -46,6 +55,8 @@ def main():
     criterion = nn.MSELoss() # TODO: - Find something better
     optimizer = optim.Adam(classifier.parameters())
 
+    wandb.watch(classifier)
+
     for epoch in range(100):
         running_loss = 0.0
         for i, (inputs, _) in enumerate(loader_sup, 0):
@@ -62,6 +73,10 @@ def main():
             # ============ Logging ============
             running_loss += loss.data
             if i % 2000 == 1999:
+                wandb.log({"Validation Accuracy": running_loss / 2000,
+                           "Epoch" : epoch + 1,
+                           "Iteration" : i+1,
+                           })
                 print('[%d, %5d] loss: %.3f' %
                       (epoch + 1, i + 1, running_loss / 2000))
                 running_loss = 0.0
diff --git a/denoise.py b/denoise.py
index b21d2cc..e9df329 100644
--- a/denoise.py
+++ b/denoise.py
@@ -10,7 +10,7 @@ def corrupt_input(corr_type, data, v):
         x_corrupted = salt_and_pepper(data, v)
 
     elif corr_type == 'gauss':
-        x_corrupted = gaussian_noise(data, v, 0.1)
+        x_corrupted = gaussian_noise(data, 0, v)
 
     elif corr_type == 'none':
         x_corrupted = data
diff --git a/pretrain.py b/pretrain.py
index 8cf8f2f..cd8ab3d 100644
--- a/pretrain.py
+++ b/pretrain.py
@@ -14,6 +14,11 @@ import torchvision
 import os
 import argparse
 
+#WANDB
+import wandb
+wandb.init(project="le-project")
+
+
 # Set random seed for reproducibility
 ''' Set Random Seed '''
 SEED = 87
@@ -23,44 +28,37 @@ if torch.cuda.is_available():
     torch.cuda.manual_seed(SEED)
 
 def main():
+    wandb.init()
+
     # Parse Args
     parser = argparse.ArgumentParser(description="Train Denoising Autoencoder")
-    parser.add_argument("--valid", action="store_true", default=False,
-                        help="Perform validation only.")
-    parser.add_argument("--perc_noise", action="store_true", default=0.1,
-                        help="Percentage of noise to add.")
-    parser.add_argument("--corr_type", action="store_true", default="gauss",
-                        help="Percentage of noise to add.")
-    parser.add_argument("--verbose", action="store_true", default=True,
-                        help="Show images as you feed them in, show reconstructions as they come out.")
+    parser.add_argument("--valid", '--do_validation',type=bool, default=False,
+                        help="Perform validation only.", metavar='v')
+    parser.add_argument("--perc_noise", '-percentage_of_noise', type=float, default=0.05,
+                        help="Percentage of noise to add.", metavar='p')
+    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="mask",
+                        help="Percentage of noise to add.", metavar='c')
+    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=False,
+                        help="Show images as you feed them in, show reconstructions as they come out.", metavar='b')
+    parser.add_argument("--wandb", '-name_of_wandb_proj', type=str, default="le-project",
+                        help="Name of WAND Project.", metavar='w')
     args = parser.parse_args()
 
+    wandb.config.update(args)
+
+
     # Create model
     ae = create_model("pretrain")
 
     ''' Load data '''
     loader_sup, loader_unsup, loader_val_sup = nyu_image_loader("../ssl_data_96", 32)
 
-    ''' Do Validation '''
-    if args.valid:
-        print("Loading checkpoint...")
-        ae.load_state_dict(torch.load("./weights/ae.pkl"))
-        dataiter = iter(loader_val_sup)
-        images, labels = dataiter.next()
-        #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
-        imshow(torchvision.utils.make_grid(images))
-
-        images = Variable(images.cuda())
-
-        decoded_imgs = ae(images)[1]
-        imshow(torchvision.utils.make_grid(decoded_imgs.data))
-
-        exit(0)
-
     # Define an optimizer and criterion
     criterion = nn.BCELoss()
     optimizer = optim.Adam(ae.parameters())
 
+    wandb.watch(ae)
+
     for epoch in range(10):
         running_loss = 0.0
         for i, (inputs, _) in enumerate(loader_sup, 0):
@@ -83,6 +81,10 @@ def main():
             # ============ Logging ============
             running_loss += loss.data
             if i % 2000 == 1999:
+                wandb.log({"Training Accuracy": running_loss / 2000,
+                           "Epoch" : epoch + 1,
+                           "Iteration" : i + 1,
+                           })
                 print('[%d, %5d] loss: %.3f' %
                       (epoch + 1, i + 1, running_loss / 2000))
                 running_loss = 0.0
@@ -93,6 +95,22 @@ def main():
         os.mkdir('./weights')
     torch.save(ae.state_dict(), "./weights/ae.pkl")
 
+    ''' Do Validation '''
+    if args.valid:
+        print("Loading checkpoint...")
+        ae.load_state_dict(torch.load("./weights/ae.pkl"))
+        dataiter = iter(loader_val_sup)
+        images, labels = dataiter.next()
+        # print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
+        imshow(torchvision.utils.make_grid(images))
+
+        images = Variable(images.cuda())
+
+        decoded_imgs = ae(images)[1]
+        imshow(torchvision.utils.make_grid(decoded_imgs.data))
+
+        exit(0)
+
 
 if __name__ == '__main__':
     main()
