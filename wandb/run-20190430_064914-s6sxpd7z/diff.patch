diff --git a/__pycache__/denoise.cpython-36.pyc b/__pycache__/denoise.cpython-36.pyc
deleted file mode 100644
index 3fbe811..0000000
Binary files a/__pycache__/denoise.cpython-36.pyc and /dev/null differ
diff --git a/__pycache__/load_data.cpython-36.pyc b/__pycache__/load_data.cpython-36.pyc
index a38cca8..bacf2a5 100644
Binary files a/__pycache__/load_data.cpython-36.pyc and b/__pycache__/load_data.cpython-36.pyc differ
diff --git a/__pycache__/models.cpython-36.pyc b/__pycache__/models.cpython-36.pyc
index d2085b0..a8f18c5 100644
Binary files a/__pycache__/models.cpython-36.pyc and b/__pycache__/models.cpython-36.pyc differ
diff --git a/__pycache__/utils.cpython-36.pyc b/__pycache__/utils.cpython-36.pyc
index 1b3830c..ab5bcf3 100644
Binary files a/__pycache__/utils.cpython-36.pyc and b/__pycache__/utils.cpython-36.pyc differ
diff --git a/classify.py b/classify.py
index 92b586f..68d8a0e 100644
--- a/classify.py
+++ b/classify.py
@@ -35,22 +35,6 @@ def main():
     ''' Load data '''
     loader_sup, loader_unsup, loader_val_sup = nyu_image_loader("../ssl_data_96", 32)
 
-    ''' Do Validation '''
-    if args.valid:
-        print("Loading checkpoint...")
-        classifier.ae.load_state_dict(torch.load("./weights/ae.pkl")) # TODO: - Check weight loading is successful
-        dataiter = iter(loader_val_sup)
-        images, labels = dataiter.next()
-        #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
-        imshow(torchvision.utils.make_grid(images))
-
-        images = Variable(images.cuda())
-
-        decoded_imgs = classifier(images)[1]
-        imshow(torchvision.utils.make_grid(decoded_imgs.data))
-
-        exit(0)
-
     # Define an optimizer and criterion
     criterion = nn.MSELoss() # TODO: - Find something better
     optimizer = optim.Adam(classifier.parameters())
@@ -88,5 +72,22 @@ def main():
     torch.save(classifier.state_dict(), "./weights/ae.pkl")
 
 
+    ''' Do Validation '''
+    if args.valid:
+        print("Loading checkpoint...")
+        classifier.ae.load_state_dict(torch.load("./weights/ae.pkl")) # TODO: - Check weight loading is successful
+        dataiter = iter(loader_val_sup)
+        images, labels = dataiter.next()
+        #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))
+        imshow(torchvision.utils.make_grid(images))
+
+        images = Variable(images.cuda())
+
+        decoded_imgs = classifier(images)[1]
+        imshow(torchvision.utils.make_grid(decoded_imgs.data))
+
+        exit(0)
+
+
 if __name__ == '__main__':
     main()
diff --git a/denoise.py b/denoise.py
deleted file mode 100644
index e9df329..0000000
--- a/denoise.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import numpy as np
-import torch
-
-def corrupt_input(corr_type, data, v):
-
-    if corr_type == 'mask':
-        x_corrupted = masking_noise(data, v)
-
-    elif corr_type == 's&p':
-        x_corrupted = salt_and_pepper(data, v)
-
-    elif corr_type == 'gauss':
-        x_corrupted = gaussian_noise(data, 0, v)
-
-    elif corr_type == 'none':
-        x_corrupted = data
-
-    else:
-        x_corrupted = None
-
-    return x_corrupted
-
-
-'''Apply masking noise by zeroing out a fraction v of the elements in X'''
-def masking_noise(X, v):
-    noise_tensor = (torch.from_numpy(np.random.uniform(0,1,X.shape)) > v).type(torch.FloatTensor)
-    return torch.mul(X, noise_tensor)
-
-'''Apply salt and pepper noise by setting a fraction v of the elements in X to the min and max values'''
-def salt_and_pepper(X, v):
-    rnd = torch.from_numpy(np.random.rand(X.shape[0], X.shape[1], X.shape[2], X.shape[3]))
-    noisy = X.clone()
-    noisy[rnd < v/2] = 0.
-    noisy[rnd > (1 - v/2)] = 1.
-    return noisy
-
-'''Apply gaussian noise by adding values sampled from a gaussian to v of the elements in X to the min and max values'''
-def gaussian_noise(X, miu, std):
-    noise = np.random.normal(loc=miu, scale=std, size=np.shape(X))
-    noise_t = torch.from_numpy(noise).type(torch.FloatTensor)
-    return torch.add(X,noise_t)
\ No newline at end of file
diff --git a/load_data.py b/load_data.py
index 6ae42b3..e5cca5a 100644
--- a/load_data.py
+++ b/load_data.py
@@ -47,7 +47,6 @@ def cifar_image_loader(path='./data', batch_size=16):
     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
     # CIFAR-10 Classes
-    classes = ('plane', 'car', 'bird', 'cat',
-               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
+    val_set = testloader
 
-    return trainloader, testloader, classes
+    return trainloader, testloader, val_set
diff --git a/models.py b/models.py
index 52920b0..adad5da 100644
--- a/models.py
+++ b/models.py
@@ -41,9 +41,9 @@ class Classifier(nn.Module):
         super(Classifier, self).__init__()
         self.ae = Autoencoder()
         self.mlp = nn.Sequential(
-            nn.Linear(3*96*96, 1000), # TODO: - Decide what h_dim to use here
+            nn.Linear(6*6*96, 256), # TODO: - Decide what h_dim to use here
             nn.ReLU(),
-            nn.Linear(1000, 10))
+            nn.Linear(256, 10))
         self.softmax = nn.Softmax()
 
     def forward(self, x):
diff --git a/noise.py b/noise.py
new file mode 100644
index 0000000..ff7b0b8
--- /dev/null
+++ b/noise.py
@@ -0,0 +1,50 @@
+import numpy as np
+import torch
+
+def corrupt_input(corr_type, data, v, cuda):
+
+    if corr_type == 'mask':
+        x_corrupted = masking_noise(data, v, cuda)
+
+    elif corr_type == 's&p':
+        x_corrupted = salt_and_pepper(data, v, cuda)
+
+    elif corr_type == 'gauss':
+        x_corrupted = gaussian_noise(data, 0, v, cuda)
+
+    elif corr_type == 'none':
+        x_corrupted = data
+
+    else:
+        x_corrupted = None
+
+    return x_corrupted
+
+
+'''Apply masking noise by zeroing out a fraction v of the elements in X'''
+def masking_noise(X, v, cuda):
+    if cuda:
+        noise_tensor = (torch.from_numpy(np.random.uniform(0,1,X.shape)) > v).type(torch.cuda.FloatTensor)
+    else:
+        noise_tensor = (torch.from_numpy(np.random.uniform(0,1,X.shape)) > v).type(torch.FloatTensor)
+    return torch.mul(X, noise_tensor)
+
+'''Apply salt and pepper noise by setting a fraction v of the elements in X to the min and max values'''
+def salt_and_pepper(X, v, cuda):
+    if cuda:
+        rnd = torch.from_numpy(np.random.rand(X.shape[0], X.shape[1], X.shape[2], X.shape[3])).type(torch.cuda.FloatTensor)
+    else:
+        rnd = torch.from_numpy(np.random.rand(X.shape[0], X.shape[1], X.shape[2], X.shape[3]))
+    noisy = X.clone()
+    noisy[rnd < v/2] = 0.
+    noisy[rnd > (1 - v/2)] = 1.
+    return noisy
+
+'''Apply gaussian noise by adding values sampled from a gaussian to v of the elements in X to the min and max values'''
+def gaussian_noise(X, miu, std, cuda):
+    noise = np.random.normal(loc=miu, scale=std, size=np.shape(X))
+    if cuda:
+        noise_t = torch.from_numpy(noise).type(torch.cuda.FloatTensor)
+    else:
+        noise_t = torch.from_numpy(noise).type(torch.FloatTensor)
+    return torch.add(X,noise_t)
\ No newline at end of file
diff --git a/pretrain.py b/pretrain.py
index cd8ab3d..857e8e9 100644
--- a/pretrain.py
+++ b/pretrain.py
@@ -4,7 +4,7 @@ import torch.optim as optim
 from load_data import *
 
 # This project
-from denoise import corrupt_input
+from noise import corrupt_input
 from utils import *
 
 # Torchvision
@@ -61,10 +61,12 @@ def main():
 
     for epoch in range(10):
         running_loss = 0.0
-        for i, (inputs, _) in enumerate(loader_sup, 0):
+        for i, (inputs, _) in enumerate(loader_unsup, 0):
             inputs = get_torch_vars(inputs)
             print(inputs.shape)
-            noised = corrupt_input(args.corr_type, inputs, args.perc_noise)
+            noised = corrupt_input(args.corr_type, inputs, args.perc_noise, args.cuda)
+            noised = get_torch_vars(noised)
+
             print("Iteration ", i)
             # ============ Forward ============
             encoded, outputs = ae(noised)
diff --git a/utils.py b/utils.py
index 09ae300..c59144c 100644
--- a/utils.py
+++ b/utils.py
@@ -5,7 +5,6 @@ from models import Autoencoder, Classifier
 import torch
 from torch.autograd import Variable
 import numpy as np
-import matplotlib.pyplot as plt
 
 ''' Instantiate Model '''
 def create_model(model_type):
@@ -45,6 +44,7 @@ def get_torch_vars(x):
 
 ''' Display Image '''
 def imshow(img):
+    import matplotlib.pyplot as plt
     npimg = img.cpu().numpy()
     plt.axis('off')
     plt.imshow(np.transpose(npimg, (1, 2, 0)))
diff --git a/wandb/debug.log b/wandb/debug.log
index 42c4e1e..a373faa 100644
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1,40 +1,15 @@
-2019-04-29 12:41:30,272 DEBUG   MainThread:19310 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
-2019-04-29 12:41:30,278 DEBUG   MainThread:19310 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,294 DEBUG   MainThread:19310 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,320 DEBUG   MainThread:19310 [run_manager.py:__init__():452] Initialized sync for le-project/e7romswt
-2019-04-29 12:41:30,324 INFO    MainThread:19310 [run_manager.py:wrap_existing_process():986] wrapping existing process 19300
-2019-04-29 12:41:30,332 DEBUG   MainThread:19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
-2019-04-29 12:41:30,381 DEBUG   MainThread:19310 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
-2019-04-29 12:41:30,391 INFO    MainThread:19310 [run_manager.py:init_run():810] system metrics and metadata threads started
-2019-04-29 12:41:30,391 INFO    MainThread:19310 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
-2019-04-29 12:41:30,403 DEBUG   Thread-13 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:30,510 DEBUG   Thread-13 :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
-2019-04-29 12:41:30,514 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():900] saving patches
-2019-04-29 12:41:30,514 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,527 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,542 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,556 DEBUG   Thread-13 :19310 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/DL_Final/DAE, universal_newlines=False, shell=None)
-2019-04-29 12:41:30,590 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():902] saving pip packages
-2019-04-29 12:41:30,591 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():904] initializing streaming files api
-2019-04-29 12:41:30,592 INFO    Thread-13 :19310 [run_manager.py:_upsert_run():911] unblocking file change observer, beginning sync with W&B servers
-2019-04-29 12:41:30,592 INFO    MainThread:19310 [run_manager.py:wrap_existing_process():1003] informing user process we are ready to proceed
-2019-04-29 12:41:30,592 INFO    MainThread:19310 [run_manager.py:_sync_etc():1059] entering loop for messages from user process
-2019-04-29 12:41:31,280 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/wandb-metadata.json
-2019-04-29 12:41:31,281 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/diff.patch
-2019-04-29 12:41:31,281 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/config.yaml
-2019-04-29 12:41:31,290 DEBUG   Thread-2  :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:31,388 DEBUG   Thread-2  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 629
-2019-04-29 12:41:31,390 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/requirements.txt
-2019-04-29 12:41:31,395 DEBUG   Thread-14 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:31,472 DEBUG   Thread-14 :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 743
-2019-04-29 12:41:31,478 DEBUG   Thread-14 :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): storage.googleapis.com:443
-2019-04-29 12:41:31,778 DEBUG   Thread-14 :19310 [connectionpool.py:_make_request():393] https://storage.googleapis.com:443 "PUT /wandb-production.appspot.com/dlc423/le-project/e7romswt/config.yaml?Expires=1556556151&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=HW8FtP3cBeCXe4Dx5JmDGaswSgDLDPkYestYt%2FGjFQRbM00Fqcwac4eKvGxGLnGrSxrDTvSsitTD%2F7w%2F3DzILAosw2aGLBFLTgRw23chxKp8vQB%2FH4x5PicaPyqA3PZIJPTNp6gdQtCwfU4b3Xfn4HHx4qheNYlIp4iFiSM5SQragfG3QS8sVPnyLmrCONzkSSUC%2BeTsupIQxQD385K8YmEEAGb2pvm2i16bQfksdYmljU%2FQC9yipl9REySOxVGPRuSLHFldWDdCSbRYKeoE0fRrp87U9BV5W7%2B2qkOHBvviPaJf1oXIFGUxY0%2FpfBhRzSWiyC5RqNtHN203CR1DfA%3D%3D HTTP/1.1" 200 0
-2019-04-29 12:41:32,609 DEBUG   Thread-6  :19310 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-04-29 12:41:32,710 DEBUG   Thread-6  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/e7romswt/file_stream HTTP/1.1" 200 312
-2019-04-29 12:41:36,658 DEBUG   Thread-6  :19310 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/e7romswt/file_stream HTTP/1.1" 200 312
-2019-04-29 12:41:37,296 INFO    Thread-2  :19310 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/DL_Final/DAE/wandb/run-20190429_164129-e7romswt/wandb-history.jsonl
-2019-04-29 12:41:37,524 INFO    MainThread:19310 [run_manager.py:_sync_etc():1110] process received interrupt signal, shutting down
-2019-04-29 12:41:37,524 INFO    MainThread:19310 [run_manager.py:_sync_etc():1163] closing log streams and sending exitcode to W&B
-2019-04-29 12:41:37,525 INFO    MainThread:19310 [run_manager.py:shutdown():918] shutting down system stats and metadata service
-9310 [e7romswt:run_manager.py:_sync_etc():1163] closing log streams and sending exitcode to W&B
-2019-04-29 12:41:37,525 INFO    MainThread:19310 [e7romswt:run_manager.py:shutdown():918] shutting down system stats and metadata service
+2019-04-30 02:49:14,938 DEBUG   MainThread:39822 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
+2019-04-30 02:49:14,944 DEBUG   MainThread:39822 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 02:49:14,955 DEBUG   MainThread:39822 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 02:49:14,978 DEBUG   MainThread:39822 [run_manager.py:__init__():452] Initialized sync for le-project/s6sxpd7z
+2019-04-30 02:49:14,983 INFO    MainThread:39822 [run_manager.py:wrap_existing_process():986] wrapping existing process 39817
+2019-04-30 02:49:15,017 DEBUG   MainThread:39822 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
+2019-04-30 02:49:15,078 DEBUG   MainThread:39822 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
+2019-04-30 02:49:15,091 INFO    MainThread:39822 [run_manager.py:init_run():810] system metrics and metadata threads started
+2019-04-30 02:49:15,091 INFO    MainThread:39822 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
+2019-04-30 02:49:15,162 DEBUG   Thread-13 :39822 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
+2019-04-30 02:49:15,275 DEBUG   Thread-13 :39822 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
+2019-04-30 02:49:15,279 INFO    Thread-13 :39822 [run_manager.py:_upsert_run():900] saving patches
+2019-04-30 02:49:15,279 DEBUG   Thread-13 :39822 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 02:49:15,292 DEBUG   Thread-13 :39822 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-04-30 02:49:15,304 DEBUG   Thread-13 :39822 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
