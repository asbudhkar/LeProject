diff --git a/__pycache__/noise.cpython-36.pyc b/__pycache__/noise.cpython-36.pyc
index 30cb3b2..285dd9a 100644
Binary files a/__pycache__/noise.cpython-36.pyc and b/__pycache__/noise.cpython-36.pyc differ
diff --git a/__pycache__/utils.cpython-36.pyc b/__pycache__/utils.cpython-36.pyc
index 12fcab0..7e80a9c 100644
Binary files a/__pycache__/utils.cpython-36.pyc and b/__pycache__/utils.cpython-36.pyc differ
diff --git a/classify.py b/classify.py
index e23fc9c..2812264 100644
--- a/classify.py
+++ b/classify.py
@@ -10,7 +10,6 @@ import torchvision
 import wandb
 
 def main():
-    wandb.init()
 
     # Parse Args
     parser = argparse.ArgumentParser(description="Train Denoising Autoencoder")
@@ -24,6 +23,8 @@ def main():
                         help="Show images as you feed them in, show reconstructions as they come out.", metavar='b')
     parser.add_argument("--wandb", '-name_of_wandb_proj', type=str, default="le-project",
                         help="Name of WAND Project.", metavar='w')
+    parser.add_argument("--wandb_on", '-is_wand_on', type=bool, default=False,
+                        help="Name of WAND Project.", metavar='w')
     args = parser.parse_args()
 
     ''' IMPORTANT: Name the weights such that there's no naming conflict between runs.'''
@@ -35,15 +36,13 @@ def main():
         raise Exception('Your pretrained weights folder is missing')
         exit(1)
 
-
-    wandb.config.update(args)
+    if args.wandb_on:
+        wandb.init()
+        wandb.config.update(args)
 
 
     # Create model
-    classifier = create_model("classify")
-
-    # Load pretrained weights
-    classifier.ae.load_state_dict(torch.load(pretrained_weight_name))
+    classifier = create_model("classify", ckpt=pretrained_weight_name)
 
     ''' Load data '''
     loader_sup, loader_val_sup, loader_unsup = nyu_image_loader("../ssl_data_96", 32)
@@ -52,10 +51,14 @@ def main():
     criterion = nn.CrossEntropyLoss()
     optimizer = optim.Adam(classifier.parameters())
 
-    wandb.watch(classifier)
+    if args.wandb_on:
+        wandb.watch(classifier)
 
-    for epoch in range(100):
+    # TODO: - Add accuracy @1 @5
+
+    for epoch in range(20):
         running_loss = 0.0
+
         for i, (inputs, labels) in enumerate(loader_sup, 0):
             inputs = get_torch_vars(inputs)
 
@@ -70,7 +73,8 @@ def main():
             # ============ Logging ============
             running_loss += loss.data
             if i % 1000 == 999:
-                wandb.log({"Finetuning Loss": running_loss / 1000,
+                if args.wandb_on:
+                    wandb.log({"Finetuning Loss": running_loss / 1000,
                            "Epoch" : epoch + 1,
                            "Iteration" : i + 1,
                            })
@@ -103,7 +107,8 @@ def main():
                     imshow(torchvision.utils.make_grid(decoded_img.data))
 
             # ============ Logging ============
-            wandb.log({"Validation Loss": val_loss})
+            if args.wandb_on:
+                wandb.log({"Validation Loss": val_loss})
             print('[%d, %5d] Validation loss: %.3f' % (epoch + 1, j + 1, val_loss))
 
     exit(0)
diff --git a/pretrain.py b/pretrain.py
index a18a91a..60fef36 100644
--- a/pretrain.py
+++ b/pretrain.py
@@ -25,21 +25,22 @@ if torch.cuda.is_available():
     torch.cuda.manual_seed(SEED)
 
 def main():
-    wandb.init()
 
     # Parse Args
     parser = argparse.ArgumentParser(description="Train Denoising Autoencoder")
     parser.add_argument("--valid", '--do_validation',type=bool, default=False,
                         help="Perform validation only.", metavar='v')
-    parser.add_argument("--perc_noise", '-percentage_of_noise', type=float, default=0.05,
+    parser.add_argument("--perc_noise", '-percentage_of_noise', type=float, default=0.2,
                         help="Percentage of noise to add.", metavar='p')
-    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="local_gauss",
+    parser.add_argument("--corr_type", '-type_of_noise', type=str, default="mask",
                         help="Percentage of noise to add.", metavar='c')
-    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=False,
+    parser.add_argument("--verbose", '-verbose_mode', type=bool, default=True,
                         help="Show images as you feed them in, show reconstructions as they come out.", metavar='b')
     parser.add_argument("--wandb", '-name_of_wandb_proj', type=str, default="le-project",
                         help="Name of WAND Project.", metavar='w')
-    parser.add_argument("--ckpt_on", '-load_weights_from_ckpt', type=bool, default=False,
+    parser.add_argument("--wandb_on", '-is_wand_on', type=bool, default=False,
+                        help="Name of WAND Project.", metavar='w')
+    parser.add_argument("--ckpt_on", '-load_weights_from_ckpt', type=bool, default=True,
                         help="Name of WAND Project.", metavar='w')
     args = parser.parse_args()
 
@@ -50,13 +51,15 @@ def main():
 
     pretrained_weight_name = os.path.join(file_path, "weights/%s/ae_%s.pkl" % (args.corr_type, str(args.perc_noise)))
 
-    wandb.config.update(args)
-
+    if args.wandb_on:
+        wandb.init()
+        wandb.config.update(args)
 
     # Create model
-    ae = create_model("pretrain")
     if args.ckpt_on:
-        ae.load_state_dict(pretrained_weight_name)
+        ae = create_model("pretrain", pretrained_weight_name)
+    else:
+        ae = create_model("pretrain")
 
     ''' Load data '''
     loader_sup, loader_val_sup, loader_unsup = nyu_image_loader("../ssl_data_96", 32)
@@ -65,7 +68,8 @@ def main():
     criterion = nn.BCELoss()
     optimizer = optim.Adam(ae.parameters())
 
-    wandb.watch(ae)
+    if args.wandb_on:
+        wandb.watch(ae)
 
     for epoch in range(40):
         running_loss = 0.0
@@ -73,6 +77,7 @@ def main():
             inputs = get_torch_vars(inputs)
             noised = corrupt_input(args.corr_type, inputs, args.perc_noise)
             noised = get_torch_vars(noised)
+            print("Iteration number: ", i)
 
             # ============ Forward ============
             encoded, outputs = ae(noised)
@@ -85,11 +90,13 @@ def main():
             if args.verbose:
                 imshow(inputs[0])
                 imshow(noised[0])
+                imshow(outputs[0].detach())
 
             # ============ Logging ============
             running_loss += loss.data
             if i % 2000 == 1999:
-                wandb.log({"Pretraining Loss": running_loss / 2000,
+                if args.wandb_on:
+                    wandb.log({"Pretraining Loss": running_loss / 2000,
                            "Epoch" : epoch + 1,
                            "Iteration" : i + 1,
                            })
diff --git a/utils.py b/utils.py
index 1a8fc49..8060eac 100644
--- a/utils.py
+++ b/utils.py
@@ -6,11 +6,18 @@ import torch
 from torch.autograd import Variable
 import numpy as np
 
+import os
+
 ''' Instantiate Model '''
-def create_model(model_type):
+def create_model(model_type, ckpt=None):
     # Create and print DAE
     if model_type == "pretrain":
         ae = Autoencoder()
+        if ckpt != None:
+            file_exists(ckpt)
+            print("Loading checkpoint ", ckpt)
+            pretrained_dict = torch.load(ckpt, map_location='cpu')
+            ae.load_state_dict(pretrained_dict)
         print_model("Encoder", ae.encoder, "Decoder", ae.decoder)
         if torch.cuda.is_available():
             ae = ae.cuda()
@@ -19,6 +26,11 @@ def create_model(model_type):
     # Create and print Classifier based on Pretrained DAE
     elif model_type == "classify":
         classifier = Classifier()
+        if ckpt != None:
+            file_exists(ckpt)
+            print("Loading checkpoint ", ckpt)
+            pretrained_dict = torch.load(ckpt, map_location='cpu')
+            classifier.ae.load_state_dict(pretrained_dict)
         print_model("Pretrained Encoder", classifier.ae.encoder, "Classifier", classifier.mlp)
         if torch.cuda.is_available():
             classifier = classifier.cuda()
@@ -42,6 +54,15 @@ def get_torch_vars(x):
         x = x.cuda()
     return Variable(x)
 
+'''Check if file exists'''
+def file_exists(filename):
+    if not os.path.isfile(filename):
+        raise Exception('The checkpoint file specified does not exist. \n'
+                        '(1) check the desired checkpoint name and location\n'
+                        '(2) disable ckpt_on (flag)')
+        exit(1)
+
+
 ''' Display Image '''
 def imshow(img):
     import matplotlib.pyplot as plt
diff --git a/wandb/debug.log b/wandb/debug.log
index 2673eea..3dedf52 100644
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1,35 +1,16 @@
-2019-05-01 12:37:50,510 DEBUG   MainThread:6314 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
-2019-05-01 12:37:50,515 DEBUG   MainThread:6314 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,527 DEBUG   MainThread:6314 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,544 DEBUG   MainThread:6314 [run_manager.py:__init__():452] Initialized sync for le-project/wgxz73j7
-2019-05-01 12:37:50,548 INFO    MainThread:6314 [run_manager.py:wrap_existing_process():986] wrapping existing process 6308
-2019-05-01 12:37:50,564 DEBUG   MainThread:6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
-2019-05-01 12:37:50,598 DEBUG   MainThread:6314 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
-2019-05-01 12:37:50,610 INFO    MainThread:6314 [run_manager.py:init_run():810] system metrics and metadata threads started
-2019-05-01 12:37:50,610 INFO    MainThread:6314 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
-2019-05-01 12:37:50,619 DEBUG   Thread-13 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:50,757 DEBUG   Thread-13 :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
-2019-05-01 12:37:50,761 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():900] saving patches
-2019-05-01 12:37:50,761 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,773 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,784 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,797 DEBUG   Thread-13 :6314 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
-2019-05-01 12:37:50,835 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():902] saving pip packages
-2019-05-01 12:37:50,838 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():904] initializing streaming files api
-2019-05-01 12:37:50,839 INFO    Thread-13 :6314 [run_manager.py:_upsert_run():911] unblocking file change observer, beginning sync with W&B servers
-2019-05-01 12:37:50,840 INFO    MainThread:6314 [run_manager.py:wrap_existing_process():1003] informing user process we are ready to proceed
-2019-05-01 12:37:50,840 INFO    MainThread:6314 [run_manager.py:_sync_etc():1059] entering loop for messages from user process
-2019-05-01 12:37:51,518 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/requirements.txt
-2019-05-01 12:37:51,521 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/config.yaml
-2019-05-01 12:37:51,529 DEBUG   Thread-2  :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:51,619 DEBUG   Thread-2  :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 685
-2019-05-01 12:37:51,621 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/diff.patch
-2019-05-01 12:37:51,622 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-metadata.json
-2019-05-01 12:37:51,626 DEBUG   Thread-14 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:51,703 DEBUG   Thread-14 :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 747
-2019-05-01 12:37:51,708 DEBUG   Thread-14 :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): storage.googleapis.com:443
-2019-05-01 12:37:52,046 DEBUG   Thread-14 :6314 [connectionpool.py:_make_request():393] https://storage.googleapis.com:443 "PUT /wandb-production.appspot.com/dlc423/le-project/wgxz73j7/config.yaml?Expires=1556728731&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=AQeyXxCkgiHXzQ4%2B%2BPKTNYnh9ZUK7he0cLUoN5Kol84UZFLkuG9x0yDOLDCowIuhwUDHx86NiNKxFa9bv03PDWn6jSQfCZHFSP8P5L0fUVzEktWYVFIA%2B6YIM2RG9L9ubb3DO1kPdx0Tnw9aMEvUCLOGZisf%2FMLWmwEvOB4Fu5K6E6CoqIgXkpA%2BSLKzR%2FH6kJ8ajuwezSx%2FqLd74qt4P5TmVSaz581Iq2D70aXPUqr16gTG939Wl2by90WVbHY9RNtip5ZOr25qtPPzErg170R3gdgzokS2TJ32m2re9M7SH%2Fl%2BhOBML5aOvOVuboaFhkVPj%2FExMamuqNzAtUb0DQ%3D%3D HTTP/1.1" 200 0
-2019-05-01 12:37:52,857 DEBUG   Thread-6  :6314 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
-2019-05-01 12:37:52,956 DEBUG   Thread-6  :6314 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /dlc423/le-project/wgxz73j7/file_stream HTTP/1.1" 200 312
-2019-05-01 12:37:54,525 INFO    Thread-2  :6314 [run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-history.jsonl
-2019-05-01 12:37:54,525 INFO    Thread-2  :6314 [wgxz73j7:run_manager.py:_on_file_created():576] file/dir created: /Users/Caetius/Desktop/LeProject/DAE/wandb/run-20190501_163749-wgxz73j7/wandb-history.jsonl
+2019-05-01 17:45:14,849 DEBUG   MainThread:11866 [wandb_config.py:_load_defaults():81] no defaults not found in config-defaults.yaml
+2019-05-01 17:45:14,853 DEBUG   MainThread:11866 [cmd.py:execute():722] Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 17:45:14,864 DEBUG   MainThread:11866 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 17:45:14,881 DEBUG   MainThread:11866 [run_manager.py:__init__():452] Initialized sync for le-project/c67e05f8
+2019-05-01 17:45:14,884 INFO    MainThread:11866 [run_manager.py:wrap_existing_process():986] wrapping existing process 11856
+2019-05-01 17:45:14,915 DEBUG   MainThread:11866 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): pypi.org:443
+2019-05-01 17:45:14,968 DEBUG   MainThread:11866 [connectionpool.py:_make_request():393] https://pypi.org:443 "GET /pypi/wandb/json HTTP/1.1" 200 31060
+2019-05-01 17:45:14,980 INFO    MainThread:11866 [run_manager.py:init_run():810] system metrics and metadata threads started
+2019-05-01 17:45:14,981 INFO    MainThread:11866 [run_manager.py:init_run():844] upserting run before process can begin, waiting at most 10 seconds
+2019-05-01 17:45:14,990 DEBUG   Thread-13 :11866 [connectionpool.py:_new_conn():823] Starting new HTTPS connection (1): api.wandb.ai:443
+2019-05-01 17:45:15,093 DEBUG   Thread-13 :11866 [connectionpool.py:_make_request():393] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 352
+2019-05-01 17:45:15,096 INFO    Thread-13 :11866 [run_manager.py:_upsert_run():900] saving patches
+2019-05-01 17:45:15,097 DEBUG   Thread-13 :11866 [cmd.py:execute():722] Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 17:45:15,109 DEBUG   Thread-13 :11866 [cmd.py:execute():722] Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 17:45:15,120 DEBUG   Thread-13 :11866 [cmd.py:execute():722] Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
+2019-05-01 17:45:15,135 DEBUG   Thread-13 :11866 [cmd.py:execute():722] Popen(['git', 'version'], cwd=/Users/Caetius/Desktop/LeProject/DAE, universal_newlines=False, shell=None)
